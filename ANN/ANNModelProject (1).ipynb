{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tkinter\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/sbekk/Downloads/housesalesprediction/kc_house_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the unnecessary columns not required for analysis\n",
    "df=df.drop(['id','date','zipcode','yr_renovated','view','waterfront'],1)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put predication column values in y and drop it from X which has other columns for prediction\n",
    "y=df['price']\n",
    "X=df.drop('price', axis=1)# df=df.values\n",
    "# X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 20 percent test and 80 percent training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "print(X_train.shape[1])\n",
    "X_test=X_test.values\n",
    "#Standardize the data\n",
    "meanValue = X_train.mean(axis=0)\n",
    "stdValue = X_train.std(axis=0)\n",
    "X_train = (X_train-meanValue) / stdValue\n",
    "X_test=(X_test-meanValue)/stdValue\n",
    "print(X_train[0])\n",
    "# define base model with neuron 130, layers=3, input=14 columns and output=1 column value, activation function relu\n",
    "def build_ann_model():\n",
    "  model = Sequential([Dense(130, activation=tf.nn.relu,input_shape=(X_train.shape[1],)),\n",
    "                      Dense(130, activation=tf.nn.relu),Dense(130, activation=tf.nn.relu),Dense(1)])\n",
    "\n",
    "  optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "  return model\n",
    "\n",
    "ann_model = build_ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rounds(Epochs=500)\n",
    "\n",
    "# Store training stats\n",
    "history = ann_model.fit(X_train, y_train, epochs=500,\n",
    "                    validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(2, input_dim=14, activation='relu'))\n",
    "# # model.add(Dense(3, activation='sigmoid'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, mae] = ann_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: ${:f}\".format(mae * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann_model.predict(X_test).flatten()\n",
    "print(y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('ANN predicted VS ground truth')\n",
    "plt.scatter(y_test, y_pred, color='r')\n",
    "plt.xlabel('Ground truth')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.axis('equal')\n",
    "plt.xlim(plt.xlim())\n",
    "plt.ylim(plt.ylim())\n",
    "_=plt.plot(y_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second way to do ann on this data but, commenting out this since it wasn't giving good mse.\n",
    "# X_train=X_train.values\n",
    "# X_test=X_test.values\n",
    "# y_train=y_train.values\n",
    "# y_test=y_test.values\n",
    "# X=X.values\n",
    "# y=y.values\n",
    "# X=X[0:20000]\n",
    "# y=y[0:20000]\n",
    "# X=X[0:1500]\n",
    "# y=y[0:1500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "# def baseline_model():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(13, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(10,kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(8,kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer='normal'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "# # evaluate model with standardized dataset\n",
    "# estimator = KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\n",
    "# type(estimator)\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "# test_predictions = baseline_model().predict(X).flatten()\n",
    "# print (test_predictions)\n",
    "# r2_score(y,test_predictions)\n",
    "# print(results)\n",
    "# def coeff_determination(y_true, y_pred):\n",
    "#     from keras import backend as K\n",
    "#     SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "#     SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "#     return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "# evaluate model with standardized dataset\n",
    "# numpy.random.seed(seed)\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "# print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anntensorflow",
   "language": "python",
   "name": "anntensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
